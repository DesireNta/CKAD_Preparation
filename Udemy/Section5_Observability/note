I. READINESS AND LIVENESS PROBES 
  -----------------------------

I.1 Readiness probes 

A pod has status and some conditions, the pod's statuds tells us where the pod is in its lifecycle. 
When a pod is created it is in pending state, this correspond at time where the schedule is trying to find where to place the pod.
Once the pod is Scheduled, it goes in ContainterCreating status. After that, i goes in running state.
The status of the pod gives us only high level summary of a POD. But some times, you may want additional information. That where the conditions comes into play. Conditions is an array of true or false values that tell us the state of a pod. 
  PodScheduled : TRUE or FALSE 
  Initialized : TRUE or FALSE
  ContainersReady : TRUE or FALSE 
  Ready : TRUE or FALSE 
To see these conditions, run kubectl describe po command and look for conditons section. 
If the pod enter in ready status, that mean the application running on it is ready to accept user traffic. 
But somme applications need a bit of time to worm up and can be running but not yet ready to be used. 

As a developer of the application, you know better what time it takes for the application to be ready. There are diffirent ways that u can define if an application inside a container is actually ready. U can set up different kinds of tests or probes which is the appropriate term in case of a web application. 
So how to u set up those tests in k8s ? 
in the pod definition file, u add a section called readinessProbe under containers section. 
 exemple : 
apiVersion : v1
kind : Pod 
metadata : 
  name : worm_up_app
  labels : 
     app : worm_up_app
spec : 
  containers : 
  - name : worm_up_app
    image : simple_app
    ports : 
    - containerPort : 8080 
    readinessProbe : 
      httpGet : 
        path : /api/ready 
        port : 8O8O 
     initialDelaySeconds : 10 
     periodSeconds : 5
There are different ways a probe can be configured. for a http use httpGet option with the path and the port. For the tcp use the tcpSocket option with the port and for executing a command specify the exec option and command. You can add an additional delay to the probe (initialDelaySeconds). if you would like to specify how often to probe, u can add the (peridoSeconds) option. by default, after 3 failed attempts the application stops, u can configure a different attempts using (failureThreshold).

I.2 LIVENESS PROBES
    ---------------
Let's say u run a container using Docker, and it starts to serve users for some reason, the application crashes and the containers process exits. the container exits as well. So as Docker is not a orchestrotor, the application remains dead. In kubernetes, when that happens, k8s tries to restart the container. 

anothe scenario is when a container continues to run but the application is not working correctly. that is where liveness comes into play. 
A liveness probe can be configured on the container to periodically thest whether the application within is actually healthy. 
As an application developer, it is up to you to define what it means for the application to be alive. 
by making a http test for web service, or tcp test for DBs or just a command to execute. 

LAB 1 Readiness and liveness Probes, to access the lab go to : https://uklabs.kodekloud.com/topic/readiness-probes-2/

1) updadate the newly crated pod with a readinessProbe using the given spec : 
   - Pod name : simple-webapp-2
   - Image Name : kodekloud/webapp-delayed-start
   - Readiness probe : httpGett
   - http probe : /ready
   - http port : 8080 
 > kubectl edit po simple-webapp-2 /add the readiness probe to the containers section. 
2) update the pod with a livenessProbe using the given spec.
   - Pod name : simple-webapp-2
   - Image name : kodekloud/webapp-delayed-start
   - liveness Probe : httpGet
   - http probe : /live
   - http port : 8080 
   - Period Seconds : 1
   - Initial delay : 80 

______ END LAB 1_______________


II   CONTAINER LOGGING 
     _________________

In Kubernets, to see logs, use the command 
> kubectl logs [OPTION] [POD_NAME], 
In a case of mutlitple container pod, u have to add the name of the container u want to see the logs. 
For the purpose of the exam, that is enough, but know that there are some advenced ways to handle logging the kubernetes. 

LAB 2 , Container logging , to access the lab go to : https://uklabs.kodekloud.com/topic/logging-2/ 

1) We have deployed a POD hosting an application. Inspect it. Wait for it to start. 
 > kubectl get po 
2) A user - USER5 - has expressed concerns accessing the application. Identify the cause of the issue. Inspect the logs of the POD 
 > kubectl logs -f webapp-1 
3) We have deployed a new POD - webapp-2 - hosting an application. Inspect it. Wait for it to start.
 > kubectl get po /With this command you notice that there are two containers running in the pod. 
4) A user is reporting issues while trying to purchase an item. Identify the user and the cause of the issue. Inspect the logs of the webapp in the POD. 
 > kubectl describe po webapp-2 /to see the names of the containers in the pod. 
 > kubectl logs webapp-2 simple-web

__________ END Lab 2 ____________

III . MONITORING IN K8s
     ------------------
How to monitor resource consumption on k8s or more importantly what would you like to monitor. 
We would like to know node level metrics such as the number of nodes in the cluster, how many of them are healthy as well as performance metrs such as CPU, memory network and disk utilization. 
We would be also intersted in POD level metrics such as the number of pods and the performance metrics of each POD. 
At the time of recording the course, kubernetes do not have a built in solution to monitor all these. however, there are some 3 party solutions such as Metric server, Prometheus, Elastic Stack, DataDog and Dynatrace.

U can have one metric server on a cluster. The metrics server retrieves metrics from each of the nodes and pod, aggregates them and store them in memory. to generate te metrics for the nodes and the pods, this is done trought kubelet agent. Kubelet contains a subcomponent known as the cAdvisor or Container advisor. this componet is responsible for reatrieving performance metrics form pods and exposing them through the kubelet api. 
To user the metric server run :

if u are using minikube : > minikube addons enable metrics-server
for other, : > git clone https://github.com/kubernetes-incubator/metrics-server 
             deploy the file in deploy/<version>
Once the deployment is done, run > kubeclt top node, this provides the cpu an memory consumption of each of the nodes.
for the pods : > kubectl top pod 

LAB 3 MONITORING to access the lab go to : https://uklabs.kodekloud.com/topic/monitoring-2/
___________________________________________________________________________________________

1) We have deployed a few PODs running workloads. Inspect them.
   > kubectl get po 
2) Let us deploy metrics-server to monitor the PODs and Nodes. Pull the git repository for the deployment files.  
   Run: git clone https://github.com/kodekloudhub/kubernetes-metrics-server.git
3) Deploy the metrics-server by creating all the components downloaded
   > cd kubernetes-metrics-server && kubectl create -f .
4) It takes a few minutes for the metrics server to start gathering data. Run the kubectl top node command and wait for a valid output.
5) Identify the node that consumes the most CPU.
  > kubectl top node 
6) Identify the POD that consumes the most Memory.
  > kubectl top pod

____________ END Lab 3 _______________________

______________________ END SECTION 5 ______________
